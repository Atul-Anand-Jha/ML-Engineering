{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Ride Anomalies\n",
    "This notebook details some basic code to get a simple clustering anomaly detection algorithm up and running. The focus here is not an optimised algorithm, but to create a simple base model from which we can explore the concepts of machine learning engineering in the rest of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "import datetime\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "rs = RandomState(MT19937(SeedSequence(123456789)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulate ride data function\n",
    "def simulate_ride_data():\n",
    "    # Simulate some ride data ...\n",
    "    ride_dists = np.concatenate(\n",
    "        (\n",
    "            10*np.random.random(size=370),\n",
    "            30*np.random.random(size=10), #long distances\n",
    "            10*np.random.random(size=10), #same distance\n",
    "            10*np.random.random(size=10) #same distance\n",
    "        )\n",
    "    )\n",
    "    ride_speeds = np.concatenate(\n",
    "        (\n",
    "            np.random.normal(loc=30, scale=5, size=370),\n",
    "            np.random.normal(loc=30, scale=5, size=10), # same speed\n",
    "            np.random.normal(loc=50, scale=10, size=10), # high speed\n",
    "            np.random.normal(loc=15, scale=4, size=10) #low speed\n",
    "        )\n",
    "    )\n",
    "    ride_times = ride_dists/ride_speeds\n",
    "\n",
    "    # Assemble into Data Frame\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'ride_dist': ride_dists, \n",
    "            'ride_time': ride_times,  \n",
    "            'ride_speed': ride_speeds\n",
    "        }\n",
    "    )\n",
    "    ride_ids = datetime.datetime.now().strftime(\"%Y%m%d\")+df.index.astype(str)\n",
    "    df['ride_id'] = ride_ids\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "First, we will read in simulated taxi ride data for processing. We assume that the typical Exploratory Data Analysis (EDA) and modelling work have been carried out in detail by the data scientists in your team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# If data present, read it in\n",
    "file_path = '../data/taxi-rides.csv'\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    df = simulate_ride_data()\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['ride_time']*60).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_dist'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_speed'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ride_dist', y='ride_time', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_label(X, create_and_show_plot=True):\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "\n",
    "    # Find labels from the clustering\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    #print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "    #print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "    #print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "    #print(\"Adjusted Rand Index: %0.3f\"\n",
    "    #      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "    #print(\"Adjusted Mutual Information: %0.3f\"\n",
    "    #      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "          % metrics.silhouette_score(X, labels))\n",
    "\n",
    "    run_metadata = {\n",
    "        'nClusters': n_clusters_,\n",
    "        'nNoise': n_noise_,\n",
    "        'silhouetteCoefficient': metrics.silhouette_score(X, labels),\n",
    "        'labels': labels,\n",
    "    }\n",
    "    if create_and_show_plot == True:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        # Black removed and is used for noise instead.\n",
    "        unique_labels = set(labels)\n",
    "        colors = [plt.cm.cool(each)\n",
    "                  for each in np.linspace(0, 1, len(unique_labels))]\n",
    "        for k, col in zip(unique_labels, colors):\n",
    "            if k == -1:\n",
    "                # Black used for noise.\n",
    "                col = [0, 0, 0, 1]\n",
    "            class_member_mask = (labels== k)\n",
    "            xy = X[class_member_mask & core_samples_mask]\n",
    "            plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                     markeredgecolor='k', markersize=14)\n",
    "            xy = X[class_member_mask & ~core_samples_mask]\n",
    "            plt.plot(xy[:, 0], xy[:, 1], '^', markerfacecolor=tuple(col),\n",
    "                     markeredgecolor='k', markersize=14)\n",
    "            \n",
    "        plt.xlabel('Standard Scaled Ride Dist.')\n",
    "        plt.ylabel('Standard Scaled Ride Time')\n",
    "        plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "        plt.show()\n",
    "    else:\n",
    "        pass\n",
    "    return run_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some nice plots\n",
    "X = df[['ride_dist', 'ride_time']]\n",
    "results = cluster_and_label(X)\n",
    "df['label'] = results['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('../output/labels.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']==-1].to_json(orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
